{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "num_inputs = 2\n",
    "num_examples = 1000\n",
    "true_w = [2,-3.4]\n",
    "true_b = 4.2\n",
    "features = torch.tensor(np.random.normal(0,0.01,size=(num_examples,num_inputs)),dtype=torch.float32)\n",
    "labels = features[:,0]*true_w[0] + features[:,1]*true_w[1] + true_b\n",
    "labels += torch.tensor(np.random.normal(0,0.01,size=labels.size()),dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([4.2349, 4.1588, 4.1795, 4.2639, 4.1839, 4.2262, 4.2065, 4.2192, 4.2074,\n        4.1591, 4.2467, 4.2019, 4.1956, 4.1946, 4.1533, 4.2199, 4.1563, 4.1717,\n        4.2598, 4.1546, 4.1212, 4.1980, 4.1880, 4.1860, 4.2178, 4.1840, 4.2227,\n        4.2310, 4.2240, 4.2004, 4.2105, 4.2372, 4.1800, 4.2137, 4.2191, 4.2306,\n        4.1305, 4.2046, 4.1684, 4.2085, 4.2895, 4.2990, 4.2116, 4.1833, 4.2054,\n        4.2393, 4.2444, 4.1347, 4.2098, 4.1732, 4.2267, 4.1666, 4.1521, 4.2245,\n        4.1344, 4.2536, 4.1898, 4.2332, 4.1853, 4.1970, 4.2328, 4.1814, 4.1754,\n        4.1642, 4.2089, 4.2024, 4.2221, 4.2080, 4.1780, 4.2312, 4.1997, 4.1981,\n        4.1322, 4.1882, 4.1479, 4.2254, 4.1854, 4.2089, 4.2156, 4.1408, 4.2340,\n        4.1974, 4.1943, 4.2019, 4.1680, 4.1687, 4.2337, 4.1857, 4.1786, 4.2229,\n        4.1378, 4.1463, 4.2401, 4.1860, 4.1351, 4.1358, 4.1371, 4.2518, 4.1630,\n        4.2191, 4.2202, 4.1702, 4.1731, 4.1891, 4.2104, 4.1836, 4.1689, 4.2203,\n        4.2666, 4.2010, 4.2093, 4.2320, 4.2329, 4.1653, 4.1377, 4.1216, 4.2476,\n        4.1793, 4.1515, 4.1692, 4.1958, 4.1991, 4.2095, 4.1973, 4.1994, 4.2298,\n        4.2598, 4.2827, 4.1277, 4.1924, 4.2037, 4.2074, 4.1449, 4.2344, 4.1600,\n        4.1407, 4.2047, 4.2716, 4.2281, 4.1993, 4.1663, 4.2496, 4.1797, 4.2900,\n        4.1735, 4.2310, 4.2211, 4.2137, 4.1493, 4.1585, 4.2067, 4.1601, 4.1863,\n        4.2216, 4.2538, 4.1359, 4.2061, 4.1878, 4.1907, 4.2236, 4.2001, 4.1969,\n        4.2241, 4.1961, 4.2138, 4.2319, 4.1579, 4.2470, 4.2475, 4.2151, 4.2273,\n        4.2174, 4.2117, 4.2034, 4.0886, 4.2236, 4.1832, 4.2088, 4.2275, 4.2429,\n        4.1913, 4.2880, 4.2203, 4.1471, 4.2048, 4.2567, 4.1992, 4.1908, 4.1465,\n        4.1760, 4.1984, 4.2797, 4.1939, 4.2181, 4.1529, 4.1716, 4.1650, 4.2445,\n        4.2571, 4.2651, 4.1722, 4.2528, 4.1583, 4.2125, 4.1246, 4.3134, 4.2017,\n        4.2273, 4.2474, 4.2188, 4.1731, 4.1779, 4.2574, 4.2179, 4.2171, 4.2657,\n        4.1920, 4.2138, 4.2140, 4.2374, 4.1498, 4.2132, 4.1980, 4.2349, 4.1781,\n        4.2244, 4.1430, 4.1065, 4.2252, 4.2966, 4.2329, 4.2064, 4.1840, 4.2720,\n        4.2075, 4.1615, 4.2443, 4.1985, 4.1968, 4.1872, 4.1695, 4.2074, 4.2017,\n        4.1735, 4.2040, 4.1682, 4.2166, 4.1890, 4.2223, 4.1940, 4.2172, 4.1553,\n        4.2349, 4.2416, 4.1772, 4.2370, 4.2260, 4.2233, 4.1949, 4.2020, 4.1859,\n        4.2412, 4.2129, 4.2049, 4.1739, 4.2450, 4.2141, 4.2181, 4.1438, 4.2277,\n        4.2008, 4.1319, 4.1539, 4.2778, 4.1823, 4.1772, 4.2116, 4.2642, 4.1875,\n        4.2287, 4.1745, 4.1818, 4.1347, 4.2082, 4.1866, 4.1706, 4.1700, 4.1802,\n        4.2208, 4.1900, 4.1835, 4.0966, 4.2337, 4.2357, 4.2584, 4.1553, 4.2332,\n        4.1334, 4.2273, 4.1955, 4.1954, 4.2583, 4.2658, 4.2306, 4.2179, 4.1728,\n        4.1692, 4.2109, 4.2086, 4.1544, 4.1545, 4.1501, 4.2287, 4.1586, 4.1559,\n        4.1249, 4.1958, 4.1966, 4.2358, 4.1548, 4.1710, 4.2612, 4.1531, 4.1569,\n        4.1638, 4.1745, 4.1953, 4.1853, 4.2411, 4.1353, 4.1760, 4.1696, 4.2379,\n        4.1900, 4.2054, 4.2234, 4.2536, 4.1790, 4.2150, 4.2431, 4.1923, 4.2178,\n        4.1414, 4.1793, 4.1643, 4.2954, 4.1961, 4.1895, 4.1964, 4.2157, 4.1249,\n        4.1940, 4.2573, 4.1506, 4.1982, 4.1404, 4.2251, 4.1709, 4.2049, 4.2312,\n        4.2218, 4.1757, 4.2348, 4.2361, 4.2674, 4.2723, 4.1303, 4.2150, 4.1622,\n        4.1790, 4.2354, 4.2311, 4.2257, 4.2751, 4.1933, 4.1384, 4.2139, 4.1725,\n        4.2975, 4.1840, 4.0951, 4.2296, 4.2592, 4.1735, 4.1853, 4.2241, 4.2150,\n        4.1564, 4.1954, 4.1844, 4.2530, 4.3064, 4.2085, 4.2436, 4.2081, 4.1927,\n        4.1702, 4.2489, 4.1642, 4.2579, 4.1208, 4.2375, 4.1821, 4.1916, 4.1323,\n        4.1690, 4.1778, 4.2122, 4.2438, 4.2308, 4.2668, 4.2498, 4.2609, 4.1710,\n        4.1659, 4.1578, 4.2114, 4.1996, 4.1625, 4.1869, 4.1876, 4.1918, 4.2154,\n        4.2482, 4.2278, 4.1871, 4.2033, 4.2484, 4.1583, 4.1351, 4.2041, 4.1305,\n        4.1486, 4.1648, 4.2604, 4.1751, 4.2584, 4.2134, 4.2230, 4.1276, 4.1122,\n        4.1506, 4.1554, 4.1707, 4.2672, 4.2316, 4.1617, 4.2032, 4.1308, 4.1416,\n        4.1850, 4.2223, 4.2779, 4.2239, 4.2039, 4.2339, 4.1619, 4.2273, 4.2953,\n        4.2279, 4.2168, 4.1795, 4.2030, 4.1990, 4.1742, 4.2229, 4.2493, 4.2102,\n        4.2600, 4.1810, 4.1695, 4.2593, 4.1844, 4.2467, 4.1597, 4.1435, 4.1860,\n        4.2184, 4.1904, 4.1882, 4.1832, 4.2205, 4.2101, 4.2132, 4.2106, 4.1855,\n        4.2647, 4.2393, 4.1910, 4.2105, 4.1856, 4.1439, 4.2032, 4.2317, 4.2307,\n        4.1901, 4.1939, 4.2666, 4.2271, 4.2559, 4.2082, 4.2400, 4.1451, 4.1061,\n        4.2169, 4.2833, 4.2375, 4.2416, 4.2432, 4.1721, 4.2104, 4.2385, 4.2034,\n        4.1921, 4.1611, 4.2563, 4.1636, 4.1843, 4.2438, 4.2004, 4.2032, 4.1897,\n        4.1665, 4.2379, 4.2558, 4.2335, 4.1730, 4.2074, 4.1739, 4.1238, 4.2811,\n        4.2390, 4.2154, 4.1881, 4.1483, 4.2201, 4.1997, 4.1881, 4.2398, 4.2194,\n        4.2357, 4.1955, 4.1808, 4.1761, 4.1880, 4.2344, 4.1128, 4.1867, 4.1560,\n        4.2029, 4.1630, 4.1378, 4.1860, 4.1990, 4.1627, 4.2203, 4.3296, 4.2002,\n        4.1702, 4.1146, 4.2049, 4.1576, 4.1662, 4.1867, 4.1287, 4.1982, 4.1732,\n        4.2328, 4.1138, 4.2373, 4.1919, 4.1924, 4.2654, 4.1785, 4.2206, 4.2058,\n        4.2455, 4.1738, 4.1356, 4.2076, 4.2291, 4.2241, 4.1996, 4.2066, 4.2338,\n        4.2102, 4.1365, 4.1399, 4.1775, 4.2006, 4.1829, 4.1994, 4.1345, 4.1963,\n        4.2000, 4.2172, 4.1548, 4.1723, 4.2178, 4.1957, 4.2322, 4.2074, 4.1984,\n        4.2153, 4.2108, 4.2759, 4.2271, 4.1735, 4.2750, 4.2057, 4.1895, 4.2097,\n        4.2358, 4.1959, 4.2348, 4.2002, 4.2299, 4.1779, 4.2152, 4.1839, 4.2360,\n        4.0979, 4.2391, 4.1699, 4.1717, 4.1998, 4.2008, 4.1919, 4.1416, 4.2057,\n        4.2338, 4.2903, 4.1515, 4.2301, 4.1661, 4.2100, 4.2261, 4.1559, 4.1423,\n        4.2380, 4.1868, 4.1978, 4.2221, 4.2067, 4.2030, 4.2666, 4.1383, 4.2054,\n        4.2047, 4.2382, 4.1940, 4.1632, 4.1845, 4.1712, 4.2141, 4.1673, 4.2364,\n        4.2457, 4.1963, 4.1238, 4.1894, 4.2812, 4.1903, 4.1740, 4.1983, 4.1843,\n        4.2067, 4.1685, 4.2303, 4.1971, 4.1116, 4.1909, 4.1531, 4.1762, 4.1544,\n        4.1901, 4.1634, 4.2373, 4.1930, 4.1609, 4.1750, 4.2305, 4.1778, 4.2237,\n        4.2671, 4.1968, 4.2109, 4.1656, 4.1740, 4.1999, 4.2899, 4.1695, 4.1360,\n        4.1780, 4.1866, 4.2039, 4.2163, 4.2030, 4.2072, 4.2518, 4.1827, 4.2146,\n        4.1539, 4.1831, 4.1908, 4.2464, 4.1770, 4.2244, 4.2876, 4.2234, 4.2133,\n        4.2261, 4.1057, 4.2140, 4.2122, 4.1863, 4.1544, 4.2701, 4.2571, 4.2228,\n        4.1830, 4.2274, 4.2404, 4.1521, 4.1815, 4.1950, 4.2541, 4.1872, 4.1476,\n        4.2231, 4.1845, 4.3122, 4.1192, 4.2584, 4.1623, 4.1917, 4.2643, 4.2253,\n        4.1168, 4.1764, 4.1182, 4.1946, 4.2423, 4.2170, 4.2093, 4.1875, 4.1504,\n        4.1797, 4.2540, 4.1664, 4.2174, 4.2336, 4.1484, 4.2298, 4.1656, 4.1780,\n        4.2155, 4.2121, 4.2138, 4.2043, 4.2216, 4.1825, 4.2473, 4.1816, 4.1011,\n        4.2020, 4.1769, 4.1740, 4.1434, 4.2386, 4.2496, 4.1778, 4.2055, 4.1981,\n        4.2001, 4.2361, 4.1784, 4.2133, 4.1694, 4.0931, 4.2302, 4.2458, 4.1463,\n        4.2523, 4.2155, 4.1714, 4.2696, 4.1981, 4.1409, 4.1921, 4.2018, 4.1969,\n        4.2483, 4.2164, 4.2200, 4.2038, 4.1511, 4.2596, 4.3054, 4.1881, 4.2120,\n        4.3124, 4.2273, 4.2382, 4.2125, 4.1479, 4.1642, 4.2278, 4.1498, 4.1886,\n        4.2086, 4.1976, 4.2136, 4.2135, 4.1919, 4.1464, 4.1757, 4.2014, 4.2651,\n        4.1502, 4.2869, 4.1548, 4.1952, 4.1168, 4.2084, 4.1958, 4.2620, 4.2124,\n        4.2053, 4.1924, 4.2055, 4.2956, 4.1255, 4.2105, 4.2576, 4.2280, 4.2463,\n        4.1779, 4.1713, 4.2174, 4.1822, 4.2232, 4.2154, 4.2429, 4.2135, 4.1959,\n        4.2323, 4.1421, 4.2325, 4.1710, 4.2068, 4.1374, 4.1961, 4.2058, 4.2420,\n        4.2000, 4.2043, 4.1607, 4.1688, 4.2263, 4.1799, 4.1969, 4.1625, 4.2471,\n        4.2006, 4.2434, 4.2466, 4.1443, 4.2164, 4.2084, 4.2271, 4.1546, 4.1878,\n        4.1801, 4.2440, 4.2019, 4.2126, 4.2109, 4.1657, 4.2099, 4.1710, 4.1069,\n        4.1265, 4.1207, 4.1194, 4.1220, 4.2145, 4.1964, 4.1954, 4.2030, 4.2782,\n        4.2323, 4.2100, 4.1882, 4.2418, 4.1934, 4.1558, 4.2124, 4.1977, 4.1766,\n        4.1975, 4.2112, 4.2131, 4.1465, 4.1735, 4.1715, 4.2710, 4.2841, 4.1736,\n        4.2229, 4.2513, 4.1563, 4.1862, 4.1736, 4.2370, 4.1992, 4.2613, 4.1962,\n        4.2498, 4.2269, 4.1970, 4.1992, 4.1633, 4.2726, 4.1740, 4.2469, 4.2404,\n        4.1134, 4.2018, 4.1615, 4.1900, 4.2832, 4.2304, 4.2783, 4.1008, 4.1551,\n        4.1546, 4.2550, 4.2495, 4.2795, 4.1827, 4.1978, 4.1717, 4.1620, 4.2231,\n        4.1973, 4.1840, 4.2361, 4.1477, 4.3031, 4.2125, 4.1857, 4.1601, 4.1550,\n        4.2115, 4.1372, 4.1846, 4.2493, 4.1972, 4.1850, 4.2007, 4.1617, 4.1360,\n        4.2161, 4.1757, 4.1539, 4.2489, 4.2080, 4.1922, 4.2327, 4.1715, 4.2064,\n        4.2281, 4.1440, 4.2128, 4.1830, 4.2073, 4.2665, 4.2254, 4.1572, 4.2595,\n        4.1924, 4.1479, 4.1730, 4.2236, 4.2450, 4.1864, 4.2058, 4.1679, 4.2099,\n        4.2281, 4.1854, 4.1696, 4.2267, 4.2045, 4.1866, 4.1689, 4.1736, 4.2136,\n        4.2503])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.0080,  0.0002],\n        [-0.0094,  0.0066],\n        [-0.0122,  0.0008],\n        ...,\n        [ 0.0038,  0.0115],\n        [-0.0037, -0.0051],\n        [ 0.0116, -0.0086]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1000, 2])"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "#读取数据\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "dataset =torch.utils.data.TensorDataset(features,labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "dataloader = DataLoader(dataset,batch_size,shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch.utils.data.dataloader.DataLoader at 0x1a29e5b3b20>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0006, -0.0050],\n",
      "        [-0.0051,  0.0009],\n",
      "        [-0.0015, -0.0055],\n",
      "        [-0.0083, -0.0072],\n",
      "        [ 0.0045,  0.0154],\n",
      "        [-0.0139, -0.0034],\n",
      "        [ 0.0010, -0.0043],\n",
      "        [ 0.0140, -0.0030],\n",
      "        [ 0.0013, -0.0081],\n",
      "        [-0.0048,  0.0087]]) tensor([4.2179, 4.1769, 4.2047, 4.2125, 4.1702, 4.1969, 4.2100, 4.2310, 4.2348,\n",
      "        4.1521])\n"
     ]
    }
   ],
   "source": [
    "for X, y in dataloader:\n",
    "    print(X, y)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liner(\n",
      "  (fc): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([[-0.6447, -0.3243]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0933], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#定义模型\n",
    "import torch.nn as nn\n",
    "class liner(nn.Module):\n",
    "    def __init__(self,n_features):\n",
    "        super(liner,self).__init__()\n",
    "        self.fc = nn.Linear(n_features,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        y = self.fc(x)\n",
    "        return y\n",
    "model = liner(num_inputs)\n",
    "print(model)\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc.weight Parameter containing:\n",
      "tensor([[-0.0013, -0.0016]], requires_grad=True)\n",
      "fc.bias Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#初始化模型参数\n",
    "from torch.nn import init\n",
    "for name,param in model.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init.normal_(param,mean=0,std=0.01)\n",
    "        print(name,param)\n",
    "    if 'bias' in name:\n",
    "        init.constant_(param, val=0)\n",
    "        print(name,param)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "loss = nn.MSELoss()\n",
    "optim = optim.SGD(model.parameters(),lr=0.03)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 0.001170\n",
      "epoch 2, loss: 0.001387\n",
      "epoch 3, loss: 0.001057\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    for X,y in dataloader:\n",
    "        out = model(X)\n",
    "        l = loss(out,y.view(-1,1))\n",
    "        optim.zero_grad()\n",
    "        l.backward()\n",
    "        optim.step()\n",
    "    print('epoch %d, loss: %f' % (epoch, l.item()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "<generator object Module.parameters at 0x000001A29E454510>"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.named_parameters at 0x000001A29E4549E0>\n"
     ]
    }
   ],
   "source": [
    "print(model.named_parameters())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc.weight Parameter containing:\n",
      "tensor([[ 0.0029, -0.0039]], requires_grad=True)\n",
      "fc.bias Parameter containing:\n",
      "tensor([4.2026], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name,param in model.named_parameters():\n",
    "    print(name,param)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "torch",
   "language": "python",
   "display_name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
